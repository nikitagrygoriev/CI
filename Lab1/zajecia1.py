# -*- coding: utf-8 -*-
"""zajecia1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YMK5BbQoTbI7qcVt0WLxDANXGECSJ-Nt

# Wstęp

Wykonaj i przeanalizuj poniższy skrypt
"""

from sklearn import datasets
import matplotlib.pyplot as plt
import random
import numpy as np

iris = datasets.load_iris()
digits = datasets.load_digits()
diabetes = datasets.load_diabetes()

print("iris: ", iris.data.shape) # macierz rozmiaru (liczba próbek, liczba cech)
print("digits: ", digits.data.shape)
print("diabetes: ", diabetes.data.shape)

print(iris.target)

digit_idx = 43

print("Etykieta cyfry: ", digits.target[digit_idx])

# wyświetlenie przykładowego obrazu
plt.figure(1, figsize=(3, 3))
plt.imshow(digits.images[digit_idx], cmap=plt.cm.gray_r, interpolation='nearest')
plt.show()

def disturb_data(X, sigma):
  return X + sigma * np.random.randn(*(X.shape))

plt.figure(1, figsize=(3, 3))
iris_reduced_data = disturb_data(iris.data[:, [1,3]], 0.3)
for d_range in [range(0, 49), range(50, 99), range(100, 149)]:
    plt.scatter(iris_reduced_data[d_range, 0], iris_reduced_data[d_range, 1])
plt.show()

"""# Zadanie 1

Policz ile jest próbek w poszczególnych klasach
"""

### solution
from collections import Counter
values, counts = np.unique(iris.target, return_counts=True)
print(values, counts)

"""# Zadanie 2

Podziel zbiór danych `iris_reduced_data` na dwie części: część treningowa (po 40 osobników z każdej klasy) i testowa (po 10 osobników każdej klasy)
Naucz naiwny klasyfikator Bayesa (`GaussianNB`) klasyfikować dane z zestawu `iris_reduced_data` (funkcja `fit` korzystająca z **części treningowej**.
Policz (korzystając z **części testowej**):
*   False positive rate (TNR)
*   True positive rate (FPR)
*   False negative rate (FNR)
*   True negative rate (FNR)
*   Dokładność (accuracy)
*   Czułość (sensitivity)
*   Swoistość (specificity)
*   Krzywą ROC

Jak zmienią się te wskaźniki gdy weźmiemy tylko po 30 osobników z każdej klasy do zbioru treningowego? Jak zmieniają się gdy zmniejszymy błąd dodawany w funkcji `disturb_data`?
"""

from matplotlib.colors import ListedColormap
import numpy as np
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB


def train(test_size, err, ind, nb_clf = GaussianNB()):
  iris_reduced_data = disturb_data(iris.data[:, [1,3]], err)

  clf = nb_clf
  
  X_train, X_test, y_train, y_test = train_test_split(
    iris_reduced_data, iris.target, test_size=test_size, random_state=42, stratify=iris.target)
  clf.fit(X_train, y_train)

  y_pred = clf.predict(X_test)

  print(f"Report for {test_size*100}% test size with error={err}: ")

  # multilabel confusion matrix here
  conf_matrix = metrics.confusion_matrix(y_test, y_pred)

  sensitivity = round(conf_matrix[ind][ind]/np.sum(conf_matrix[ind,:]),2)       #TPR
  specificity = round(np.sum(np.delete(np.delete(conf_matrix, ind, 1), ind, 0))/np.sum(np.delete(conf_matrix, ind, 0)),2)        #TNR
  fnr = round((1 - sensitivity),2)      #fall-out
  fpr = round((1 - specificity),2)      #miss rate

  accuracy = round((np.sum(np.delete(np.delete(conf_matrix, ind, 1), ind, 0)) + conf_matrix[ind][ind]) / np.sum(conf_matrix),2)
  ppv = round(conf_matrix[ind][ind]/np.sum(conf_matrix[ : , ind]),2)
  npv = round(np.sum(np.delete(np.delete(conf_matrix, ind, 1), ind, 0))/np.sum(np.delete(conf_matrix, ind, 1)),2)


  print('Sensitivity(TPR): ',sensitivity, ', Specificity(TNR): ',specificity, 
        ', Fall-out(FNR): ', fnr, ', Miss Rate(FPR): ', fpr,
        ', PPV: ', ppv, ', NPV: ',npv, ', Accuracy(ACC)',accuracy)
  print('Confusion Matrix:\n',conf_matrix,'\n')
  

for i in ([.5,.1,0],[.5,.1,1],[.5,.1,2]):
  train(i[0],i[1],i[2])

"""# Zadanie 3

Powtórz zadanie 2, ale dla klasyfikatora SVM. Użyj kerneli `rbf` i `linear`. Porównaj działanie dla wartości parametru `C=1.0, 10.0, 0.1`. Dla kernela `rbf` przetestuj różne opcje skalowania cech (parametr `gamma`: wartosci `scale`, `auto`, `1.0`, `10.0`, `0.1`.
"""

from sklearn.svm import SVC

cs = [1.0, 10.0, 0.1]
gammas = ['scale','auto',1.0,10.0,0.1]
kernels = 'rbf','linear'
for kernel in kernels:
  for c in cs:
    if kernel=='rbf':
      for gamma in gammas:
        clf = SVC(C=c, gamma=gamma, kernel=kernel)
        print(f'Results for kernel={kernel} with c={c} gamma={gamma}\n')
        for i in ([.5,.1,0],[.5,.1,1],[.5,.1,2]):
          train(i[0],i[1],i[2]) 
    else:
      clf = SVC(kernel=kernel)
      print(f'Results for kernel={kernel} with gamma={gamma}\n')
      for i in ([.5,.1,0],[.5,.1,1],[.5,.1,2]):
        train(i[0],i[1],i[2])

"""# Zadanie 4

Znajdź najlepsze (pod względem dokładności) parametry klasyfikatora SVM z użyciem 5-krotnej walidacji krzyżowej: kernel, $C$, wybrany parametr kernela. Przeszukaj przynajmniej 100 zestawów wartości.

Czy te same parametry zapewniają najlepszą wartość innych metryk?

Wykorzystaj `from sklearn.model_selection import KFold`
"""

from sklearn.model_selection import KFold
from sklearn.svm import SVC

def evaluate_classifier(C):
  scores = []
  kf = KFold(n_splits=5)
  X = iris_reduced_data
  y = iris.target
  for train_index, test_index in kf.split(X, y):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    clf = SVC(gamma=gamma, kernel=kernel, C=C)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    #print(round(metrics.accuracy_score(y_test, y_pred),2),end=' ')
    scores.append(metrics.accuracy_score(y_test, y_pred)) 
  return np.array(scores)

resultsBestParams = np.array([[0,0,0,0,0]])
for kernel in ['linear','rbf']:
  for gamma in ['scale','auto',1.0,10.0,0.1]:
    for C in [1.0, 3.0, 0.3]:
      #print(f"\nkernel={kernel} gamma={gamma} C={C}")
      resultsBestParams = np.concatenate((resultsBestParams, [evaluate_classifier(C)]), axis=0)

result = []
resultsBestParams = np.delete(resultsBestParams, 0, 0)
for i in [0,1,2,3,4]:
  result.append([np.argmax(resultsBestParams[:,i]), np.amax(resultsBestParams[:,i])])
  print('Split',i+1,'\tIndex: ',np.argmax(resultsBestParams[:,i]), '\t Value: ',np.amax(resultsBestParams[:,i]))

#print(result)

#print(resultsBestParams)